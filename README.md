# Internships

## Deadlines

letter deadline | program | notes
--- | --- | ---
2018-01-18 | [SIParCS](#siparcs) | Higher priority. I will definitely apply.
2018-01-29 | [NSF MSGI](#nsf-msgi) | Low priority. I am waiting for a response from the program coordinator.

## What I will submit

material | link
--- | ---
cover letter(s) | in progress
CV | <https://coltongrainger.com/cv>
transcripts | [this pdf](transcripts/2019-01-05-total-transcript.pdf)

My cover letter will focus on 

- my technical skill in scientific computing, and
- how statistical and computational experience will support my career goal to do topological data analysis

## What I am applying for

I am applying for summer internships at two labs in Boulder, CO. 

### SIParCS

Program overview:

> The goal of the SIParCS program is to make a long-term, positive impact on the quality and diversity of the workforce needed to use and operate 21st century supercomputers. Graduate students and undergraduate students (who have completed their sophomore year by summer 2019) gain significant hands-on experience in high-performance computing and related fields that use HPC for scientific discovery and modeling.
>
> This program embeds students as summer interns in the Computational and Information Systems Laboratory, an organization within NCAR charged with provisioning supercomputing and data systems to the geosciences research community. The roles of service and research in CISL support NCAR’s broad scientific mission of discovery in the atmospheric and related sciences.

I am applying for 2 projects under the umbrella of SIParCS. They are:

#### project on historical data

> Building a Historical Data Image Archive to Support Climate Research and Retrospective Research of Hand-Written Documents 
> 
> Areas of interest: Digital Asset Management
>
> It is estimated that more than 50% of the pre-1960 ocean and atmosphere observed data are not in digital form.  These logbooks from ships and land observation stations hold valuable numerical data dating back two centuries and more.  The process to make these data accessible for climate and weather research has two major steps, first photographic images are made from the paper pages, and second the numerical data are key entered by individuals through citizen science efforts and dedicated professionals.  This project addresses the preservation and access to the images, or documents as they are called in the library sciences, for the purposes of validating information coming out of the key entry process and for the rich textual comments that add information about historical weather and life events over time.  We will research the underlying technologies available to design, and build a prototype repository containing the digital images/documents, catalog them, and provide user access to review and copy them.  Project will be appropriately scaled with applicant strengths/educational background.
> 
> Skills and Qualifications:  
> Basic understanding of programming languages such as Python.  Basic understanding of controlled vocabularies and metadata schemas.  Basic understanding of XML and HTML markup languages.  Experience with database query languages such as SQL.  Familiarity with digital provenance concepts.  Ability to interact with mentors and peers in a manner that supports collaboration and inquiry.  Ability to work with diverse staff.  Good problem solving skills.  Good oral and written communication skills.  Willingness to learn and use computing tools and programs.  Overt curiosity to explore new things.  

#### project on climate models

> Applying Machine Learning to Maximize Information Extraction from Imperfect Climate Models
>
> Areas of interest: Data science, Geostatistics
> 
> To study the Earth’s current and future climate, scientists use physically based computational models to represent the earth system.  One challenge scientists face is that all such models are imperfect.  Often that imperfection results in coherent biases in space and time that a human can readily interpret, but humans have limited mental bandwidth. Modern machine learning algorithms provide an opportunity to make better use of existing models by retrieving more of the information available in these imperfect models in an automated fashion. This problem is particularly important for regional climate studies because the enormous computational cost of running higher resolution models means that regional climate models are either lower resolution than desired (with larger potential for errors) or have greater simplifications in their physical representation (with larger potential for errors).
>  
> This project will have a student apply machine learning techniques to an archive of regional climate model simulations to improve our understanding of local scale changes in climate that are critical for end users.  By leveraging existing simulations performed for historical time periods, a student will be able to explore the trade-offs associated with different algorithms and different regional climate modeling approaches in comparison to observations.  This work will also provide an opportunity to use and learn modern data science parallel analysis platforms (e.g. xarray, dask, and tensorflow) on the NCAR supercomputer (Cheyenne) and associated GPU accelerated analysis platform (Casper).
> 
> Skills and Qualifications:  
Basic programming skills required, strong preference for familiarity with unix and python (or R).  Applicants should have an interest in earth science, and ideally have taken a statistics course.  

### NSF MSGI

I am tentatively applying to this program. I will update this section after I hear back from the program coordinator.

## Thank you!

A strong letter might

> address the student’s academic records and potential for success in an internship, as indicated by communication and teamwork skills.
